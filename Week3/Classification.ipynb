{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "How to classify information - whether it is email/spam, sentiment, type of website, image classification, etc...\n",
    "\n",
    "Sentiment Classifer - takes a sentence and determines if it is positive or negative\n",
    "\n",
    "Classifier applications - takes an input, passes it through a classifer model, outputs an output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Classifiers\n",
    "\n",
    "Uses a static set of words that are positive & negative. Someone has to pre-populate\n",
    "\n",
    "Does not accomodate that words have different degrees of sentiment\n",
    "\n",
    "Does not address that single words are not good enough\n",
    "\n",
    "## Linear Classifiers\n",
    "\n",
    "Use training data to assign a weight to every word (ie. -1.0, -0.5, +3.0)\n",
    "\n",
    "Uses weights of words in a sentence to determine a score\n",
    "\n",
    "great = 1.2, awesome = 1.7, terrible = -2.1\n",
    "\n",
    "Score(x) = 1.2 + 1.7 - 2.1 = +0.8 (positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision boundaries\n",
    "\n",
    "Linear Classifiers need to use boundaries to determine weights\n",
    "\n",
    "Decision boundaries separates positive & negative predictions (ie. 1 awful == 2 goods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Classification models\n",
    "\n",
    "In classifiers model errors are different than in regression model\n",
    "\n",
    "You still have a training data set and test data set\n",
    "\n",
    "## Classification error\n",
    "\n",
    "In your training data set, you have a \"sentence\" and a \"Label\" (ie. positive/negative).  \n",
    "\n",
    "Send your training data set \"sentences\" only through the system, hiding the \"Label\". \n",
    "\n",
    "Determine if the classifer gets things correct or has mistakes by compairing the generated \"Label\" with the training data set \"label\"\n",
    "\n",
    "*Error* = # of mistakes / total # of test sentences (Best possible answer == 0.0)\n",
    "\n",
    "*Accuracy* = # of correct / total # of test sentences (Best possible answer = 1.0)\n",
    "\n",
    "(Error) = 1 - (Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Accuracy\n",
    "\n",
    "If you randomly guess positive/negative, your accuracy will be 0.5 (50%).  You classifer should be better than this.\n",
    "\n",
    "If you have (k) # of classification classes (ie. financial, politics, local news), if you randomly guess your accuracy will be 0.33 (33%).  Your classifer should be better than this.\n",
    "\n",
    "If you classifier w/ 90% accuracy good?  Depends ....\n",
    "* If your data is 90% skewed to one side, your accuracy might not be that good.\n",
    "\n",
    "When you determine your accuracy, to determine if it is good or not, determine:\n",
    "* Is there class imbalance?\n",
    "* How does it compare to a simple baseline approach (ie. random guessing, Classification classes)?\n",
    "* What accuracy does my appliation need?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of mistakes\n",
    "\n",
    "* True Positive = When statement is positive and you predict positive\n",
    "* True Negative = When statement is negative and you predict negative\n",
    "\n",
    "* Fales Negative = When statement is positive, but you predict negative\n",
    "* False Positive = When statement is negative, but you predict positive\n",
    "\n",
    "Costs of different type of mistakes can be different!\n",
    "* False negative of spam == annoying\n",
    "* False negative of missed diagnosis of medical issue == disease not treated\n",
    "\n",
    "Confusion Matrix === Difference between true label and predicted label  \n",
    "100 test examples\n",
    "* 50 true positive\n",
    "* 35 true negatives\n",
    "* 10 false positive\n",
    "* 5 false negative\n",
    "\n",
    "accuracy = 85/100 = 0.85\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much data does a model need to learn?\n",
    "\n",
    "* More the merrier, but data quality is most important\n",
    "* Theoretical techniques sometimes can bound how much data is needed\n",
    "* In practice, more complex models require more data.  Emprical analysis can provide guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curves\n",
    "\n",
    "* Test error decreases  as you have more training data\n",
    "* Test error cannot go to zero even if you add more training data. \n",
    "* Difference between test error and zero == BIAS of model\n",
    "\n",
    "Bias = even with infinite data, test error will not go to zero\n",
    "\n",
    "More complex models tend to have less bias!\n",
    "* This is because they do more complex comparisons/classifications that impprove accuracy, so error goes down, but needs more data to get accurate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Probabilities\n",
    "Most classifiers provide a probability / confidence level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
