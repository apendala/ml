{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend items based on past history, history of similar profiles, etc....\n",
    "Amazon has long history.\n",
    "Netflix's 1M prize to improve recommendation system accuracy did a lot to bootstrap the effort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Personalization** is transforming our experience of the world. There is too much information overload, so you need personalization to help make it consumable.  **Personalization: Connects users & items**.  users and items can be of the same type (ie. facebook friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to combine:\n",
    "* **global and session** interests \n",
    "* **adapt over time**\n",
    "* **recommendations form coherent & diverse sequence** (ie. music play lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of recommender systems:\n",
    "* Netflix: what videos to recommend you\n",
    "* Amazon: what items to purchase based on history, similar shoppers, etc...\n",
    "* Spotify: recommended music play lists\n",
    "* Facebook: recommended friends\n",
    "* Drug-target interactions: recommend what drugs to use for different issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 0: Popularity\n",
    "\n",
    "* used a lot by news sites (ie. Most popular articles)\n",
    "\n",
    "* Limitation: No personalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 1: Classification model (Decisioning?)\n",
    "\n",
    "* Uses features of products & users to make recommendations.  This adds in a bit of personalization\n",
    "\n",
    "* takes in user info, purchase history, prouct info, other info and passes into classfier model.  Returns yes or no\n",
    "\n",
    "Pro:\n",
    "* Personalized: considers user info & purchase history\n",
    "* Features can capture context: time of the day, what I just saw\n",
    "* Even handles limited user history: Age, etc...\n",
    "\n",
    "Limitations:\n",
    "* Features may not be avilable\n",
    "* Often doesn't perform as well as collaborative filtering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 2: Collaborative Filtering (Co-occurrence matrices) methods\n",
    "\n",
    "ie. People who bought this (ie. diapers) also bought ... (ie. wipes)\n",
    "\n",
    "**Co-occurrence matrix** (Matrix C):\n",
    "* stores # of users who bought both items i & j\n",
    "* (# of items) x (# of items) matrix\n",
    "* symetric: # purchasing i & j same as # for j & i\n",
    "\n",
    "You basically have vectors:\n",
    "* diapers = [ dvd=0, ..., pacifier=4, ... , wipe=100, ...]\n",
    "\n",
    "You now can sort the vector and use the items with highest count for recommendations\n",
    "\n",
    "You **MUST** normalize a co-occurrence matrix because having counts for very popular items will drown out other items.\n",
    "\n",
    "Normalization types: \n",
    "\n",
    "**Jaccard similarity** normalizes by popularity but limitation is that only current page matters - no history\n",
    "* (# of people who purchased i AND j) / (# of people who purchased i OR j)\n",
    "\n",
    "**Weighted Average** uses a weight of your purchaes history to determine what to recommend to you.  Doesn't utilize context, user features, product features.  Also has a cold start problem (what if a new user or product arrives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 3: Matrix Factorization: Discovering hidden structure \n",
    "\n",
    "Take example of rating movies in Netflix.  There are many users and they watch a variety of movies. For each movie they watch, they rate them.  \n",
    "\n",
    "If you build a matrix of users vs. moving rating, the matrix will have some data, but there is a lot of unknown values as a user doesn't watch all movies.  How can you predict what the user will rate the unwatched movies using **both** the **ratings the user gave for movies they watched** and the **ratings other users gave for movies they watched** \n",
    "\n",
    "Suppose we had d topics for each user and movie so we could make a vector for each movie\n",
    "\n",
    "Movie Vector (Rv) = [action=0.3, ..., romance=0.01, ... , drama=1.5]\n",
    "\n",
    "User Vector (Lu) = [action=2.5, ... , romance=0, ... , drama=0.8]\n",
    "\n",
    "(Rv) x (Lu) == (0.3 * 2.5) + (0 * 0.01) + (1.5 * 0.8) =  \n",
    "\n",
    "You can use a *Matrix Factorization model* to calculate predicted ratings.  There are amany efficient algorithsms for factorization.\n",
    "\n",
    "One limitation is the Cold start problem - can't handle new user or no user\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features capture context (ie. time of day, what I just saw, past purchases)\n",
    "\n",
    "Discovered topics from matrix factorization capture groups of users who behave similarily (ie. women from seattle who teach and have a baby)\n",
    "\n",
    "To mitigate cold-start problem, combine both feature and discovered topics to predict their expecxted ratings.\n",
    "\n",
    "\n",
    "**Blending of models** is really poular to squeezing last bit of accuracy.  This is what was done by Netflix and winning team blended over 100 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metric for recommender systems\n",
    "\n",
    "Cannot use **classification accuracy** (fraction of items correctly classified as liked vs. not liked) because we don't care what they don't like & we need to quickly discover the relatively few liked items\n",
    "\n",
    "* **Recall** \n",
    "\n",
    "= (# shown that I like) / (# I like in sample set) \n",
    "\n",
    "how much a recommended set of items cover what I like\n",
    "\n",
    "maximize recall by showing everything == 1\n",
    "\n",
    "*  **Precision**\n",
    "\n",
    "= (# shown that I like) / (# shown from sample set)\n",
    "\n",
    "how much do I have to look at to see what I like\n",
    "\n",
    "optimial recommender only shows what I like\n",
    "\n",
    "Use **Precision-Recall curve** to evaluate performance\n",
    "* vary threshold on # of items recommended\n",
    "* ideal curve is horizontal line (0,1) to (1,1)\n",
    "* realistic curve is jagged reverse expoential going to (1,0)\n",
    "* Largest area under the curve (AUC) is algorithm with best performance\n",
    "* Antoher method is to set desired recall and maximize precision **(precision at k)**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
